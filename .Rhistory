ggtitle("Estimativa") +
theme_hc()
pp<-ggplot(data=pnew, aes(x=Data, y=predicao)) +
geom_line() +
stat_smooth(method = lm)+
scale_x_date(labels = date_format("%d")) +
scale_y_continuous() +
geom_text(aes(label=round(predicao,2)), vjust=3, colour="black") +
ggtitle("Estimativa") +
theme_hc()
pp
pp<-ggplot(data=pnew, aes(x=Data, y=predicao)) +
geom_line() +
stat_smooth(method = lm)+
scale_x_date(labels = date_format("%d")) +
scale_y_continuous() +
scale_x_continuous() +
geom_text(aes(label=round(predicao,2)), vjust=3, colour="black") +
ggtitle("Estimativa") +
theme_hc()
pp
pp<-ggplot(data=pnew, aes(x=Data, y=predicao)) +
geom_line() +
stat_smooth(method = lm)+
#scale_x_date(labels = date_format("%d")) +
scale_y_continuous() +
scale_x_continuous() +
geom_text(aes(label=round(predicao,2)), vjust=3, colour="black") +
ggtitle("Estimativa") +
theme_hc()
pp
pp<-ggplot(data=pnew, aes(x=Data, y=predicao)) +
geom_line() +
stat_smooth(method = lm)+
scale_x_date(labels = date_format("%d")) +
scale_y_continuous() +
geom_text(aes(label=round(predicao,2)), vjust=3, colour="black") +
ggtitle("Estimativa") +
theme_hc()
pp
knitr::opts_chunk$set(echo = TRUE)
ts(consumo)
ts(agg_modelo)
frequency(agg_modelo)
summary(agg_modelo)
plot(agg_modelo)
plot(agg_modelo$vtotal)
abline(reg=lm(vtotal~time(Data)))
abline(reg=lm(agg_modelo, vtotal~time(Data)))
abline(reg=lm(vtotal~time(Data), agg_modelo))
cycle(agg_modelo$vtotal)
plot(aggregate(agg_modelo$vtotal,FUN=mean))
install.packages("forecast")
library(forecast)
ts(agg_modelo)
myts <- ts(agg_modelo)
plot(myts)
fit <- HoltWinters(myts)
knitr::opts_chunk$set(echo = TRUE)
length(unique(consumo$Mesa))
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data("concrete")
install.packages("caret")
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
str(testing)
(
)
fit <- train(CompressiveStrength ~ ., method = "lm", data=testing)
finmod <- fit$finalModel
print(finmod)
plot(finmod$residuals, p ch=19)
plot(finmod$residuals, pch=19)
plot(finmod$fitted, finmod$residuals, pch=19)
plot(finmod$residuals,colour=Cement ,pch=19)
install.packages("googleVis")
library(googleVis)
data(cars)
View(cars)
install.poackages("DT")
install.packages('DT')
require('DT')
d = data.frame(
cars,
stringsAsFactors = FALSE
)
dt <- datatable(d, filter = 'bottom', options = list(pageLength = 5)) %>%
formatStyle('V1',
color = styleInterval(c(0.5, 56), c('black', 'red', 'blue')),
backgroundColor = styleInterval(56.5, c('snow', 'lightyellow')),
fontWeight = styleInterval(58.0, c('italics', 'bold')))
require('DT')
d = data.frame(
cars,
stringsAsFactors = FALSE
)
dt <- datatable(d, filter = 'bottom', options = list(pageLength = 5)) %>%
formatStyle('speed',
color = styleInterval(c(0.5, 56), c('black', 'red', 'blue')),
backgroundColor = styleInterval(56.5, c('snow', 'lightyellow')),
fontWeight = styleInterval(58.0, c('italics', 'bold')))
dt
data(cars)
cars
data("Fruits")
View(Fruits)
data("Fruits")
head(Fruits)
head(Fruits)
library(shiny)
install.packages("shiny")
version()
version
install.packages("tm")
library(tm)
library(tm)
file <- choose.files(deault = "",caption = "Select files", multi = FALSE )
file <- choose.files(deault = "",caption = "Select files", multi = FALSE )
file <- choose.files(caption = "Select files", multi = FALSE )
RawData <- readPDF(file)
install.packages("Rpoppler")
PDF_info(file)
install.packages("pdftools")
library(pdftools)
RawData <- pdf_text(file)
Data2 <- cat(RawData[2])
Data2 <- cat(RawData[2])
toc <- pdf_toc(file)
fonts <- pdf_fonts(file)
View(fonts)
remove(fonts)
remove(toc)
Data3 <- cat(RawData[3])
Data2
head(RawData)
head(strsplit(Data3[ [  1 ] ], "\n")[ [ 1 ] ])
head(strsplit(RawData[[  3 ]], "\n")[[ 3 ]])
RawData[[3]]
RawData[3]
head(strsplit(RawData[  3 ], "\r\n")[ 3 ])
strsplit(RawData[3], "\r\n")
data3 <- strsplit(RawData[3], "\r\n")
data3
data3[27]
data3[,27]
data.frame(data3)
data3 <- data.frame(strsplit(RawData[3], "\r\n"))
View(data3)
grep("34%", data3)
table_data <- RawData[ [ 3 ] ] %>%
str_split(pattern = "\n") %>%
unlist()
library(dplyr)
library(dplyr)
table_data <- RawData[ [ 3 ] ] %>%
str_split(pattern = "\n") %>%
unlist()
library(tidyr)
table_data <- RawData[ [ 3 ] ] %>%
str_split(pattern = "\n") %>%
unlist()
table_data <- RawData[ [ 3 ] ] %>%
strsplit(pattern = "\n") %>%
unlist()
table_data <- RawData[ [ 3 ] ] %>%
strsplit("\r\n") %>%
unlist()
table_data <- RawData[ [ 3 ] ] %>%
strsplit(split =  "\r\n") %>%
unlist()
library(stringr)
table_data <- RawData[ [ 3 ] ] %>%
str_split(pattern = "\r\n") %>%
unlist()
table_data <- RawData[ [ 3 ] ] %>%
str_split(pattern = "\r\n") %>%
unlist()
str_split(RawData[ [ 3 ] ], pattern = "\r\n")
str_split(RawData[[3 ]], pattern = "\r\n") %>%
unlist()
data(segmentationOriginal)
library(caret)
library(dplyr)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
View(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list=FALSE)
training <- createDataPartition[inTrain,]
testing <- createDataPartition[-inTrain,]
training <- createDataPartition[inTrain,]
data(iris);
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.7, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
library(caret)
fit <- train(Case~ .,data=training,method="rpart",prox=TRUE)
install.packages('e1071', dependencies=TRUE)
fit <- train(Case~ .,data=training,method="rpart",prox=TRUE)
fit <- train(Case~ .,data=training,method="rpart")
print(fit$finalModel)
head(training)
str(training)
str(training$TotalIntenCh2)
str(training$FiberWidthCh1)
str(training$PerimStatusCh1)
plot(fit$finalModel, uniform=TRUE,
main="Classification Tree")
plot(fit$finalModel, uniform=TRUE)
plot(fit$finalModel, uniform=TRUE,
main="Classification Tree")
text(fit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(rattle)
install.packages("rattle")
library(rattle)
library(rattle)
fancyRpartPlot(fit$finalModel)
install.packages("rpart.plot")
library(rattle)
fancyRpartPlot(fit$finalModel)
p <- predict(modFit,newdata=testing)
p <- predict(fit
p <- predict(fit,newdata=testing)
p <- predict(fit,newdata=testing)
head(p)
p
fit$finalModel
fancyRpartPlot(fit$finalModel)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.6, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
set.seed(125)
fit <- train(Case~ .,data=training,method="rpart")
print(fit$finalModel)
fancyRpartPlot(fit$finalModel)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6, list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit$finalModel
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
inTrain <- createDataPartition(y=segmentationOriginal$Case, p=0.6, list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6, list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit$finalModel
fit <- train(Case~ .,data=training,method="rpart")
print(fit$finalModel)
fancyRpartPlot(fit$finalModel)
fancyRpartPlot(modFit$finalModel)
p <- predict(fit,newdata=testing)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6, list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
modFit <- train(Class ~ ., method = "rpart", data = training)
library(caret)
library(dplyr)
library(ggplot2)
library(AppliedPredictiveModeling)
library(rattle)
library(caret)
library(dplyr)
library(ggplot2)
library(AppliedPredictiveModeling)
library(rattle)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6, list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
#2. Set the seed to 125 and fit a CART model with the rpart method using all predictor variables and default caret settings.
#3. In the final model what would be the final model prediction for cases with the following variable values:
data(segmentationOriginal)
inTrain <- createDataPartition(y = segmentationOriginal$Case, p = 0.6, list = FALSE) # 60% training
training <- segmentationOriginal[inTrain, ]
testing <- segmentationOriginal[-inTrain, ]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit$finalModel
fancyRpartPlot(modFit$finalModel)
library(pgmm)
install.packages("pogmm")
library(pgmm)
library(pgmm)
install.packages("pgmm")
library(pgmm)
library(pgmm)
data(olive)
olive = olive[,-1]
data(olive)
View(olive)
olive = olive[,-1]
View(olive)
modFit <- train(Area ~ ., method = "rpart", data = olive)
modFit$finalModel
fancyRpartPlot(modFit$finalModel)
newdata = as.data.frame(t(colMeans(olive)))
p <- predict(fit,newdata=newdata)
p <- predict(modFit,newdata=newdata)
p
library(ElemStatLearn)
install.packages("ElemStatLearn")
data(SAheart)
data(SAheart)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
View(SAheart)
str(SAheart)
modFit <- modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, method = "glm", family = "binomial" ,data = trainSA)
modFit <- modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,data = trainSA , method = "glm", family = "binomial" )
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
modelSA <- train(chd ~ .,
data = trainSA, method = "glm", family = "binomial")
modFit <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,data = trainSA , method = "glm", family = "binomial" )
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(testSA, modFit)
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
missClass(testSA$chd, predict(modelSA, newdata = testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
str(vowel.test)
View(vowel.train)
set.seed(33833)
modFit <- train(Species~ .,data=training,method="rf",prox=TRUE)
modFit <- train(y~ .,data=vowel.train,method="rf",prox=TRUE)
varImp(modFit)
varImp(modFit$finalModel)
gbmImp <- varImp(modFit, scale = FALSE)
fit  <- randomForest(y~., data=vowel.train)
gbmImp <- varImp(fit, scale = FALSE)
varImp(fit)
fit  <- randomForest(y~., data=vowel.train, importance=T)
varImp(fit)
order(varImp(fit))
order(varImp(fit), decreasing = T)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
fit
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(modFit$finalModel)
fancyRpartPlot(fit$finalModel)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
fit1  <- randomForest(y~., data=vowel.train, importance=T)
fit2 <- train(y ~ ., method="gbm",data=vowel.train,verbose=FALSE)
fit1 <- train(y~ .,data=vowel.train,method="rf",prox=TRUE)
p1 <- predict(fit1, newdata = vowel.test)
p2 <- predict(fit2, newdata = vowel.test)
p1
table(p1, vowel.test)
table(data.frame(p1), vowel.test)
p1 <-data.frame(predict(fit1, newdata = vowel.test))
View(p1)
p2 <- data.frame(predict(fit2, newdata = vowel.test))
table( p1$predict.fit1..newdata...vowel.test., vowel.test)
names(p1) <- "pred"
table( p1$pred, vowel.test)
confusionMatrix(p1, vowel.test$y)
confusionMatrix(p1, vowel.test$y)$overall
confusionMatrix(p1, vowel.test$y)$overall[1]
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
fit1 <- train(y~ .,data=vowel.train, method="rf")
fit2 <- train(y ~ .,data=vowel.train, method="gbm")
fit1 <- train(y~ .,data=vowel.train, method="rf")
fit2 <- train(y ~ .,data=vowel.train, method="gbm")
p1 <- data.frame(predict(fit1, newdata = vowel.test))
p2 <- data.frame(predict(fit2, newdata = vowel.test))
confusionMatrix(p1, vowel.test$y)$overall[1]
p1 <- predict(fit1, newdata = vowel.test)
p2 <- predict(fit2, newdata = vowel.test)
confusionMatrix(p1, vowel.test$y)$overall[1]
confusionMatrix(p2, vowel.test$y)$overall[1]
t <- data.frame(p1,p2, y = vowel.test)
sum(p1[t$p1 == t$p2]
)
View(t)
sum(p1[t$p1 == t$p2] ==
t$y[t$p1 == t$p2])
sum(p1[t$p1 == t$p2] ==
t$y[t$p1 == t$p2]) /
sum(t$p1 == t$p2)
t$p1 == t$p2
sum(t[t$p1 == t$p2] ==
t$y[t$p1 == t$p2])
t <- data.frame(p1,p2, y = vowel.test$y)
sum(t[t$p1 == t$p2] ==
t$y[t$p1 == t$p2])
sum(t[t$p1 == t$p2])
t[t$p1 == t$p2]
p1[t$p1 == t$p2]
sum(p1[t$p1 == t$p2] ==
t$y[t$p1 == t$p2]) /
sum(t$p1 == t$p2)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
set.seed(3433)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(62433)
srt(training)
View(training)
mod_rf <- train(diagnosis ~ .,data=training, method="rf")
mod_gbm <- train(diagnosis ~ .,data=training, method="gbm")
mod_lda <- train(diagnosis ~ .,data=training, method="lda")
pred_rf <-  predict(mod_rf, newdata = testing)
pred_gbm <-  predict(mod_gbm, newdata = testing)
pred_lda <-  predict(mod_lda, newdata = testing)
pred_all <- data.frame(pred_rf, pred_gbm, pred_lda, testing$diagnosis)
mod_rf_all <- train(diagnosis ~ ., data=pred_all, method="rf")
mod_rf_all <- train(diagnosis ~ ., data=pred_all, method="rf")
View(pred_all)
pred_all <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = pred_all)
mod_rf_all <- train(diagnosis ~ ., data=pred_all, method="rf")
final <- predict(mod_rf_all, pred_all)
final
confusionMatrix(mod_rf_all, training$diagnosis)$overall[1]
confusionMatrix(mod_rf_all, training$diagnosis)$overall[1]
confusionMatrix(mod_rf_all, testing$diagnosis)$overall[1]
confusionMatrix(mod_rf, testing$diagnosis)$overall[1]
confusionMatrix(pred_rf, testing$diagnosis)$overall[1]
confusionMatrix(pred_gbm, testing$diagnosis)$overall[1]
confusionMatrix(pred_lda, testing$diagnosis)$overall[1]
confusionMatrix(pred_rf_all, testing$diagnosis)$overall[1]
confusionMatrix(final, testing$diagnosis)$overall[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
?plot.enet
install.packages("elasticnet")
mod_lasso <- train(CompressiveStrength ~ ., data=training, method="lasso")
?plot.enet
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
library(lubridate) # For year() function below
install.packages("lubridate")
library(lubridate)
library(lubridate)
file <- choose.files()
file <- choose.files()
file <- choose.files()
dat = read.csv(file)
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
bats
library(forecast)
?bats
bats(training)
bats(tstrain)
bts <- bats(tstrain)
forecast <- forecast(bts, testing)
forecast <- forecast(bts)
plot(forecast)
fcast <- forecast(bts, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) /
dim(testing)[1]
library(plyr)
library(dplyr)
library(ggplot2)
library(caret)
library(randomForest)
library(rattle)
source('C:/Users/paulo.morone/Dropbox/Data Science - Coursera/8.Practical Machine Learning/finalProject.R', echo=TRUE)
setwd("C:/Users/paulo.morone/Dropbox/Data Science - Coursera/8.Practical Machine Learning")
source('C:/Users/paulo.morone/Dropbox/Data Science - Coursera/8.Practical Machine Learning/finalProject.R', echo=TRUE)
pred_rf_final
View(testing)
print(mod_rf, digits = 4)
mod_rf
mod_lda
mod_lda$resample$Accuracy
mean(mod_lda$resample$Accuracy)
